{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e895638",
   "metadata": {},
   "source": [
    "Shivani Joshi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268797d",
   "metadata": {},
   "source": [
    "(Project Intern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb17f4",
   "metadata": {},
   "source": [
    "IKS center of Jain Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e379d3c",
   "metadata": {},
   "source": [
    "School Of Data Science and Forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8a40c",
   "metadata": {},
   "source": [
    "DAVV Indore (M.P.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdaa50b",
   "metadata": {},
   "source": [
    "# Duration\n",
    "\n",
    "1 Jul 2023 to 31 Dec 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2c15c",
   "metadata": {},
   "source": [
    "# Sources Collection:\n",
    "\n",
    "We gather a variety of materials during the sources collection phase that can be used to enhance the project's knowledge base. These include:\n",
    "\n",
    "To understand existing research, methodologies, and best practices, a literature review is conducted to review academic papers, articles, and books relevant to the project's domains.\n",
    "\n",
    "To access open-source projects, code snippets, and community contributions, explore online repositories, such as GitHub or other code-sharing platforms.   \n",
    "\n",
    "Analyzing official documentation of relevant technologies and libraries to gain a deeper understanding of their functionalities, use cases, and implementation details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb51d5",
   "metadata": {},
   "source": [
    "# Exploration of Python Libraries:\n",
    "\n",
    "With Python's versatility, there are a wide variety of libraries available for diverse use cases. The exploration phase involves:\n",
    "\n",
    "Identification of Relevant Libraries:\n",
    "\n",
    "Determining Python libraries that are aligned with the project's objectives. Consider factors such as functionality, community support, and ease of integration.\n",
    "\n",
    "Prototyping and testing: Evaluating the performance, compatibility, and suitability of selected libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ce60a",
   "metadata": {},
   "source": [
    "# Preservation of manuscripts\n",
    "\n",
    "Manuscript preservation is an important undertaking that includes arranging historical texts chronologically in a methodical manner and taking proactive steps to advance Jainalogy in periodicals. This two-pronged strategy seeks to preserve the historical and cultural legacy ingrained in these texts while also promoting Jainology awareness through user-friendly and interesting platforms.\n",
    "\n",
    "Manuscripts are carefully curated and categorized, frequently covering a wide range of subjects and eras. This entails placing them in chronological order to follow the development of Jain knowledge and philosophy across time.\n",
    "\n",
    "Every manuscript is annotated with comprehensive metadata that includes contextual details like the author, the date of creation, and the relevance of the work historically. Researchers can better comprehend the manuscripts in light of their larger historical context with the use of this metadata.\n",
    "\n",
    "The indexing and cross-referencing of manuscripts enhances research scope and understanding of Jain philosophy and history by establishing links between various texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04085029",
   "metadata": {},
   "source": [
    "By systematically collecting sources, exploring Python libraries, and assessing advanced technologies, these steps performed by project team by this they can make informed decisions, optimize resource utilization, and lay a solid groundwork for successful project execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e9ef2",
   "metadata": {},
   "source": [
    "# OCR Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500019ce",
   "metadata": {},
   "source": [
    "### Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151fb13",
   "metadata": {},
   "source": [
    "Jaina Mathematics Manuscripts Digitalization with Machine Learning/Artificial Intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059df42",
   "metadata": {},
   "source": [
    "### Aim of the Project\n",
    "\n",
    "The digitalization of ancient manuscript is a crucial objective for libraries all around the world in order to protect and provide access to our culture legacy, valuable knowledge and innovation that may have been overlooked due to the exclusive reliance on traditional data retention methods in ancient times but which could prove beneficial for future advancement. So we are aiming to develop an AI/ML system to automatically transcribe handwritten historical manuscripts for prevention and research purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecde01e",
   "metadata": {},
   "source": [
    "### Literature Review \n",
    "\n",
    "The transcription of historical manuscripts represents a critical endeavor in preserving and unlocking the rich tapestry of human history and culture. Manuscript often fragile and written in antiquated scripts offers invaluable insights into bygone eras. This literature review aims to survey the historical context, significance and scholarly work related to manuscript transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2cb221",
   "metadata": {},
   "source": [
    "#### 1.\tHistorical Context – \n",
    "\n",
    "Manuscripts handwritten documents created before the advent of printing technology, have long been considered a primary source for understanding the past. Throughout history, they have served as repositories of knowledge, religious texts, legal documents and literary works.\n",
    "In India, Manuscripts have been instrumental in preserving and transmitting knowledge, culture and spirituality for centuries, leaving a lasting impact on the country’s history and heritage.\n",
    "The first sacred text in India such as the Vedas and Upanishads were painstakingly inscribed on palm leaves during the ancient Vedic era. On palm leaves and birch bark Buddhist writing like Tripitaka and Jain literature like the Agamas were written down and illustrated. India experienced a thriving manuscripts culture, with universities in Nalanda and Vikramashila producing manuscripts on various subjects, including mathematics, astronomy, literature and art in the middle age. Manuscripts were produced in scripts such as Devanagari, Grantha, Bengali and Tamil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136ceeb",
   "metadata": {},
   "source": [
    "#### 2.  Significance – \n",
    "\n",
    "Transcribing historical manuscript is crucial as they often face deterioration due to time, environmental factors and frailty. Transcription helps preserve content, broaden audiences, and aids in deciphering archaic scripts and languages, enhancing historical context understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6587d7",
   "metadata": {},
   "source": [
    "#### 3.\tScholarly Work on Manuscript Transcription – \n",
    "\n",
    "1. TY  - JOUR, AU  - Bhosle, Sujata, AU  - Deshmukh, Ratnadeep, PY  - 2014/06/01, SP  - 257, EP  - 260, N2  - Abstract— In this paper, we describe the procedure of developing dataset for offline handwritten Sanskrit character recognition. There is no standard dataset available for handwritten characters. Researcher has to develop own character dataset. This paper will provide a way for researcher to develop a dataset for offline handwritten Sanskrit character recognition. This paper describes use of Hough Transform and Euclidean Distance classifier for recognition. This paper describes basics of dataset, challenges associated with it and its processing. T1  - Offline handwritten Sanskrit character recognition, VL  - 2, JO  - Annales Universitatis Mariae Curie-Sklodowska sectio AA – Chemia, ER  -\n",
    "\n",
    "\n",
    "2. Scius-Bertrand A, Jungo M, Wolf B, Fischer A, Bui M. Transcription Alignment of Historical Vietnamese Manuscripts without Human-Annotated Learning Samples. Applied Sciences. 2021; 11(11):4894. https://doi.org/10.3390/app11114894\n",
    "\n",
    "\n",
    "3. Shih, Y. (2011). Machine Learning Final Project: Handwritten Sanskrit Recognition using a Multi-class SVM with K-NN Guidance.\n",
    "\n",
    "\n",
    "4. TY  - JOUR, AU  - Singh, Shailendra, AU  - Sachan, Manoj, PY  - 2017/07/01, SP  - 18, EP  - 22, N2  - The rapid growth in the field of internet facilities and digitalization, changes the living way of human being. Due to internet facilities and services, anyone can access data from anywhere. A lot of online data are generating day by day, so that data needs to be processed before extracting the information. Therefore the demand of Natural language Processing (NLP) Techniques has been increased. The Pattern recognition is sub-field of NLP. The field of Pattern Recognition is a branch of machine learning that contributed up to great extent in the Computer Vision and Machine Vision applications. Pattern Recognition is concerned with the recognition of patterns and regularities in data. Handwriting recognition is one of the challenging subtask and current research field under Pattern Recognition, due to different ways of writing and handwriting styles. Handwritten Sanskrit Characters recognition is more complicated than other languages works in online and offline mode, because Sanskrit characters have more consonants and modifiers. In this paper discussed the opportunities and challenges of Handwritten Sanskrit Character Recognition System. T1  - Opportunities and Challenges of Handwritten Sanskrit Character Recognition System, VL  - 3, JO  - , ER  -\n",
    "\n",
    "\n",
    "5. Sandeep Dwarkanath Pande, Pramod Pandurang Jadhav, Rahul Joshi, Amol Dattatray Sawant, Vaibhav Muddebihalkar, Suresh Rathod, Madhuri Navnath Gurav, Soumitra Das,Digitization of handwritten Devanagari text using CNN transfer learning – A better customer service support, Neuroscience Informatics, Volume 2, Issue 3, 2022, 100016,ISSN 2772-5286, https://doi.org/10.1016/j.neuri.2021.100016. (https://www.sciencedirect.com/science/article/pii/S2772528621000169) Abstract: Devanagari script is one of the bases of various language scripts in India. With the growth of computing and technology, manual systems are replaced by automated one. The purpose of this research is to automate the existing manual system for digitization of Devanagari script with the use of an automated approach so that it saves time, antique data. The prescriptions given by the expert doctors and the treatments which are present in ancient Vedic literature are useful for handling patients with serious diseases. Digitization helps in easy access, manipulation, and longer storage of this data. Unlike Western languages such as English, Devanagari, is a famous script in India which does not have formal digitization tools. This work employs the best suited techniques that are useful to enhance the recognition rate and configures a Convolutional Neural Network (CNN) for effective Devanagari handwritten text recognition (DHTR). This approach uses Devanagari handwritten character dataset (DHCD) which is a vigorous open dataset with 46 classes of Devanagari characters and each of this class has two thousand different images. After recognition, conflict resolution is subtle for effective recognition therefore, this approach provides an arrangement to the user to handle the conflicts. This approach obtains promising results in terms of accuracy and training time. Keywords: Devanagari image to text; Transfer learning; Devanagari text digitization; CNN for Devanagari text recognition; Alexnet\n",
    "\n",
    "\n",
    "6. Dr. Sunil L. Bangare1 , Ketan S Gore2 , Ganesh S. Waghmare3 , Bhagyashri Bhoi4 , Mallika Marndi5 Associate Professor, Department of Information Technology1 UG Scholar, Department of Information Technology2,3,4,5 Sinhgad Academy of Engineering, Pune, Maharashtra, India. ‘Vedic’ Sanskrit Language Character Recognition from Images using CNN and OCR. Volume 2, Issue 5, May 2022. Abstract: Many scholars have recently been interested in deep learning and character recognition. Deep neural networks exhibit cutting-edge performance in many classification and identification issues. The Optical Character Recognition (OCR) algorithm takes an optical picture of a character as input and provides the corresponding character with its current meaning and execution time as output. It has several uses, including traffic surveillance, robotics, and the digitalization of printed documents. Convolutional Neural Network (CNN), a prominent deep neural network design, may be used to construct OCR. The standard CNN classifiers are capable of learning the significant 2D characteristics contained in pictures and classifying them using the soft-max layer. The CNN is used to extract features. Several common CNN classifiers were investigated in order to discover optimal CNN for extracting features that may be utilised in combination with ECOC classifier for accurate recognition of handwritten or any character in Sanskrit. The given handwritten character image dataset is used to train and evaluate the CNN-ECOC. The simulation results reveal that CNN provides greater accuracy and somewhat different meaning than the classic CNN classifier. Keywords: Character recognition; Classification; CNN; Deep learning; OCR; SVM\n",
    "\n",
    "\n",
    "7. Mir Mojtaba Mirsalehi, Optical Information Processing, Editor(s): Robert A. Meyers, Encyclopedia of Physical Science and Technology (Third Edition), Academic Press, 2003, Pages 335-369, ISBN 9780122274107, https://doi.org/10.1016/B0-12-227410-5/00525-1. (https://www.sciencedirect.com/science/article/pii/B0122274105005251)\n",
    "\n",
    "\n",
    "8. S. Grieggs et al., \"Measuring Human Perception to Improve Handwritten Document Transcription,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, no. 10, pp. 6594-6601, 1 Oct. 2022, doi: 10.1109/TPAMI.2021.3092688.\n",
    "\n",
    "\n",
    "9. Aditi Moudgil, Saravjeet Singh, Vinay Gautam, Shalli Rani, Syed Hassan Shah, Handwritten devanagari manuscript characters recognition using capsnet, International Journal of Cognitive Computing in Engineering, Volume 4, 2023, Pages 47-54, ISSN 2666-3074, https://doi.org/10.1016/j.ijcce.2023.02.001. (https://www.sciencedirect.com/science/article/pii/S2666307423000049) Abstract: Manuscripts serve as a wealth of knowledge for future generations and are a useful source of information for locating material from the Middle Ages. Ancient manuscripts can be found in handwritten form, thus they must be translated into digital form so that computing equipment can access them and additional indexing and search operations can be performed with ease. Manuscript recognition is already possible using a variety of methods. Regional languages like Devanagari, Gurmukhi, Sanskrit, etc., however, have very few methods available. In this study, the Devanagari characters from the manuscripts is recognised using a CapsNet-based method. 33 fundamental characters, 3 conjuncts, and 12 modifiers make up the Devanagari alphabet. The complete dataset is divided into 399 classes for the recognition of basic, modifiers, and conjunct characters. Due to spatial relationship, CapsNet is used to recognize the handwritten characters. The proposed model was run using 10:70, 20:80, and 30:70 as test: train ratio of characters. Also, the number of epochs was varied for better recognition accuracy. The authors observed the best recognition accuracy of 94.6% was achieved to recognize the Devanagari characters using CapsNet. Keywords: Optical character recognition; Ancient documents; Innovative tool; Machine learning; Hindi\n",
    "\n",
    "\n",
    "10. Kha Cong Nguyen, Cuong Tuan Nguyen, Masaki Nakagawa, Nom document digitalization by deep convolution neural networks, Pattern Recognition Letters, Volume 133, 2020, Pages 8-16, ISSN 0167-8655, https://doi.org/10.1016/j.patrec.2020.02.015 (https://www.sciencedirect.com/science/article/pii/S0167865520300556) Abstract: Nom is an ancient script used in Vietnam until the current Latin-based Vietnamese alphabet became common, and a large number of ancient Nom documents are in existence. Due to the gradual degradation of Nom documents and a decrease in the number of scholars who can understand them, a system to digitalize Nom documents is urgently necessary. This paper presents a segmentation-based method for digitalizing Nom documents using deep convolution neural networks. Nom pages are preprocessed, segmented into isolated characters, and then recognized by a single-character OCR. The structure of the U-Net is applied to create segmentation maps and extract character regions from them. Subsequently, we propose coarse and fine combined classifiers to recognize each character pattern. The results by the best classifier are revised by a decoder using a langue model. The decoder is the same as the connectionist temporal classification decoder used in end-to-end text recognition systems. Compared with the traditional segmentation method using projection profiles and the Voronoi diagram (IoU = 81.23%), the segmentation method using the deep convolution neural network produces a better result (IoU = 92.08%) for detecting character regions. The proposed CNN models for recognizing segmented character patterns outperforms the traditional models using the modified quadratic discriminant function and the learning vector quantization with the recognition rate of 85.07%. The combination of coarse and fine classifiers, the training dataset with salt and pepper noises, and the attention layer are the key factors in the recognition rate improvement.\n",
    "\n",
    "\n",
    "11. Opu, Md & Hossain, Md & Kabir, Ashad. (2023). Handwritten Bangla character recognition using convolutional neural networks: a comparative study and new lightweight model. Neural Computing and Applications. 1-12. 10.1007/s00521-023-09008-8. \n",
    "\n",
    "\n",
    "12. Baldominos A, Saez Y, Isasi P. A Survey of Handwritten Character Recognition with MNIST and EMNIST. Applied Sciences. 2019; 9(15):3169. https://doi.org/10.3390/app9153169\n",
    "\n",
    "\n",
    "13. Y. Gurav, P. Bhagat, R. Jadhav and S. Sinha, \"Devanagari Handwritten Character Recognition using Convolutional Neural Networks,\" 2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE), Istanbul, Turkey, 2020, pp. 1-6, doi: 10.1109/ICECCE49384.2020.9179193."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448f683",
   "metadata": {},
   "source": [
    "### Working on \n",
    "\n",
    "First off, we have created a state-of-the-art technology for digitizing manuscripts and producing high-quality photographs or scans. This method provides precise and clear representations while guaranteeing the preservation of priceless content.\n",
    "\n",
    "We have used sophisticated image processing techniques to improve the photographs' quality and eliminate any noise or texturing. We have obtained outstanding outcomes by utilizing the strength of the OpenCV package, which is known for its aptitudes in image processing and computer vision jobs. For image modification and format conversions, we have also looked into other libraries like Pillow.\n",
    "\n",
    "Additionally, we are concentrating on image segmentation and filtering tasks using the Python Scikit-Image module. Our research in this field has comprised reading blog posts, research papers and website articles to better our comprehension of the segmentation process and increase the effectiveness of its various algorithms. We are concentrating on segmenting the dataset's text character images.\n",
    "\n",
    "We initially tested with Google's Tesseract OCR technology to extract text from the photos. However, we discovered that its text extraction accuracy for the Sanskrit language was unsatisfactory. We are now developing our own OCR engine from the ground up as a result. We are also looking into different OCR technologies to ensure precise text extraction.\n",
    "\n",
    "We will now concentrate on Natural Language Processing (NLP) going forward. In order to further improve the capabilities of our solution, we already evaluated a few NLP libraries, including inltk, and we intend to include them into our system.\n",
    "\n",
    "We have incorporated libraries like PyPDF2 and PIL into our system to handle many file formats, including PDF and picture files. certain libraries make it possible to process and manipulate certain file types without any difficulty.\n",
    "\n",
    "To achieve a thorough and effective solution, we also used other crucial libraries like TensorFlow and Keras during the development process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd6c30",
   "metadata": {},
   "source": [
    "#### Some work snipets are down here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7c1aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\os\\anaconda3\\lib\\site-packages (from pytesseract) (9.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\os\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\os\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.4)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7339b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALTONotSupported', 'Output', 'TSVNotSupported', 'TesseractError', 'TesseractNotFoundError', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'get_languages', 'get_tesseract_version', 'image_to_alto_xml', 'image_to_boxes', 'image_to_data', 'image_to_osd', 'image_to_pdf_or_hocr', 'image_to_string', 'pytesseract', 'run_and_get_output']\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "print(dir(pytesseract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150fb002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__bool__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    }
   ],
   "source": [
    "print(dir(__package__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73426e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ALTONotSupported', <class 'pytesseract.pytesseract.ALTONotSupported'>), ('Output', <class 'pytesseract.pytesseract.Output'>), ('TSVNotSupported', <class 'pytesseract.pytesseract.TSVNotSupported'>), ('TesseractError', <class 'pytesseract.pytesseract.TesseractError'>), ('TesseractNotFoundError', <class 'pytesseract.pytesseract.TesseractNotFoundError'>), ('__builtins__', {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x000002D3410F6B20>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'WindowsError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': See https://www.python.org/psf/license/, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x000002D340DA3670>, 'runfile': <function runfile at 0x000002D340E6DAF0>, '__IPYTHON__': True, 'display': <function display at 0x000002D33EFBE9D0>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000002D341130100>>}), ('__cached__', 'C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract\\\\__pycache__\\\\__init__.cpython-39.pyc'), ('__doc__', None), ('__file__', 'C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract\\\\__init__.py'), ('__loader__', <_frozen_importlib_external.SourceFileLoader object at 0x000002D341181CA0>), ('__name__', 'pytesseract'), ('__package__', 'pytesseract'), ('__path__', ['C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract']), ('__spec__', ModuleSpec(name='pytesseract', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000002D341181CA0>, origin='C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract\\\\__init__.py', submodule_search_locations=['C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract'])), ('__version__', '0.3.10'), ('get_languages', <function get_languages at 0x000002D34360D9D0>), ('get_tesseract_version', <function get_tesseract_version at 0x000002D34360DAF0>), ('image_to_alto_xml', <function image_to_alto_xml at 0x000002D34360DCA0>), ('image_to_boxes', <function image_to_boxes at 0x000002D34360DD30>), ('image_to_data', <function image_to_data at 0x000002D34360DE50>), ('image_to_osd', <function image_to_osd at 0x000002D34360DEE0>), ('image_to_pdf_or_hocr', <function image_to_pdf_or_hocr at 0x000002D34360DC10>), ('image_to_string', <function image_to_string at 0x000002D34360DB80>), ('pytesseract', <module 'pytesseract.pytesseract' from 'C:\\\\Users\\\\os\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract\\\\pytesseract.py'>), ('run_and_get_output', <function run_and_get_output at 0x000002D34360D700>)] <function isfunction at 0x000002D33CD3BD30>\n"
     ]
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "\n",
    "# Importing math module\n",
    "import pytesseract as mt\n",
    "\n",
    "# Printing all the functions in math module\n",
    "print(getmembers(mt), isfunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621b4a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ocr-nanonets-wrapper\n",
      "  Downloading ocr-nanonets-wrapper-1.1.tar.gz (4.2 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\os\\anaconda3\\lib\\site-packages (from ocr-nanonets-wrapper) (2.27.1)\n",
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\os\\anaconda3\\lib\\site-packages (from ocr-nanonets-wrapper) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\os\\anaconda3\\lib\\site-packages (from ocr-nanonets-wrapper) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\os\\anaconda3\\lib\\site-packages (from pandas->ocr-nanonets-wrapper) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\os\\anaconda3\\lib\\site-packages (from pandas->ocr-nanonets-wrapper) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\os\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->ocr-nanonets-wrapper) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\os\\anaconda3\\lib\\site-packages (from requests->ocr-nanonets-wrapper) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\os\\anaconda3\\lib\\site-packages (from requests->ocr-nanonets-wrapper) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\os\\anaconda3\\lib\\site-packages (from requests->ocr-nanonets-wrapper) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\os\\anaconda3\\lib\\site-packages (from requests->ocr-nanonets-wrapper) (3.3)\n",
      "Building wheels for collected packages: ocr-nanonets-wrapper, fpdf\n",
      "  Building wheel for ocr-nanonets-wrapper (setup.py): started\n",
      "  Building wheel for ocr-nanonets-wrapper (setup.py): finished with status 'done'\n",
      "  Created wheel for ocr-nanonets-wrapper: filename=ocr_nanonets_wrapper-1.1-py3-none-any.whl size=4720 sha256=449f93e3a18a98f4d7dfdc1e8b45455f4623259012fe5d4b55b80f72f4339b04\n",
      "  Stored in directory: c:\\users\\os\\appdata\\local\\pip\\cache\\wheels\\1b\\d8\\48\\6bc54a8bc43c4153fd7aa9dfb7ad8b28fc292b01421240cc07\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40723 sha256=e2fb40db0f8b5614fb46d6409dbc1574a229103a60153052ae3bee1af4085c95\n",
      "  Stored in directory: c:\\users\\os\\appdata\\local\\pip\\cache\\wheels\\44\\35\\8b\\86ce00cec7e4d13c5f189680ae0fa82f919bedc066c2cddae9\n",
      "Successfully built ocr-nanonets-wrapper fpdf\n",
      "Installing collected packages: fpdf, ocr-nanonets-wrapper\n",
      "Successfully installed fpdf-1.7.2 ocr-nanonets-wrapper-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install ocr-nanonets-wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351c5ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f895603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.74-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\os\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.0.74\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3ee923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\os\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\os\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c985044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install inltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import setup\n",
    "\n",
    "language_code = 'sa'\n",
    "\n",
    "setup(language_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aafb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af0285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁अवि', 'श्', 'राम', 'ं', '▁वह', 'ेत्', '▁भार', 'ं', '▁शीतोष्ण', 'ं', '▁च', '▁न', '▁विन्दति', '▁।', '▁स', 'सन्तोष', '▁', 'स्तथा', '▁नित्यं', '▁त्रीणि', '▁शिक्ष', 'ेत', '▁', 'गर्दभ', 'ात्', '▁॥']\n"
     ]
    }
   ],
   "source": [
    "#try-outs NLP libraries\n",
    "\n",
    "san_text = \"\"\" अविश्रामं वहेत् भारं शीतोष्णं च न विन्दति ।\n",
    "ससन्तोष स्तथा नित्यं त्रीणि शिक्षेत गर्दभात् ॥\"\"\"\n",
    "\n",
    "print(tokenize(san_text, \"sa\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import get_similar_sentences\n",
    "\n",
    "# get similar sentences to the one given in sanskrit\n",
    "output = get_similar_sentences('जीविताशा बलवती धनाशा दुर्बला मम्।।',2, 'sa')\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Perform OCR on an image containing Sanskrit text\n",
    "def ocr_sanskrit_image(image_path):\n",
    "    try:\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Perform OCR with Sanskrit language\n",
    "        ocr_result = pytesseract.image_to_string(image, lang=\"hi\")\n",
    "\n",
    "        \n",
    "        print(ocr_result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "ocr_sanskrit_image(r\"C:\\Users\\os\\Downloads\\manuscript_page-0001.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cdbf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\os\\anaconda3\\lib\\site-packages (from PyPDF2) (4.7.1)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\os\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc928de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'PageObject' object has no attribute 'to_image'\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Function to extract text from a PDF file using OCR\n",
    "def ocr_sanskrit_pdf(pdf_path):\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        total_pages = len(pdf.pages)\n",
    "\n",
    "        for page_num in range(total_pages):\n",
    "            page = pdf.pages[page_num]\n",
    "            image = page.to_image()\n",
    "            ocr_result = pytesseract.image_to_string(image, lang=\"san\")\n",
    "            print(f\"Page {page_num + 1} OCR Result:\\n{ocr_result}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "ocr_sanskrit_pdf(r\"C:\\Users\\os\\Downloads\\manuscript.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader\n",
    "import io\n",
    "\n",
    "# Function to extract images from a PDF page\n",
    "def extract_images_from_page(page):\n",
    "    images = []\n",
    "    if '/XObject' in page['/Resources']:\n",
    "        xObject = page['/Resources']['/XObject'].get_object()\n",
    "        for obj in xObject:\n",
    "            if xObject[obj]['/Subtype'] == '/Image':\n",
    "                data = xObject[obj].get_data()\n",
    "                image = Image.open(io.BytesIO(data))\n",
    "                images.append(image)\n",
    "    return images\n",
    "\n",
    "# Function to perform OCR on extracted images\n",
    "def ocr_images(images):\n",
    "    ocr_results = []\n",
    "    for image in images:\n",
    "        ocr_result = pytesseract.image_to_string(image, lang=\"san\")\n",
    "        ocr_results.append(ocr_result)\n",
    "    return ocr_results\n",
    "\n",
    "# Function to perform OCR on a PDF file\n",
    "def ocr_sanskrit_pdf(pdf_path):\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        total_pages = len(pdf.pages)\n",
    "\n",
    "        for page_num in range(total_pages):\n",
    "            page = pdf.pages[page_num]\n",
    "            images = extract_images_from_page(page)\n",
    "            ocr_results = ocr_images(images)\n",
    "\n",
    "            for i, result in enumerate(ocr_results):\n",
    "                print(f\"Page {page_num + 1}, Image {i + 1} OCR Result:\\n{result}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "ocr_sanskrit_pdf(r\"C:\\Users\\os\\Downloads\\manuscript.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d9f4f",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "We are starting our effort to create a thorough module and coordinating APIs that are uniquely suited for the recognition of Sanskrit Handwritten Characters.\n",
    "\n",
    "We will set out to choose and improve the best ML model architecture with the highest precision. Our keen eye directs us to the combination of a transformer-based model, a recurrent neural network, and a convolution neural network to provide unmatched accuracy and efficiency and will also perform advanced Data Augmentation techniques to further increase the strength of our model. This tactical strategy enables our system to perform above and beyond all expectations by empowering it to exceed its own constraints.\n",
    "\n",
    "We rigorously assess our model as part of our never-ending quest for excellence. We thoroughly examine it to ensure its accuracy and to identify any potential flaws. We will use the skills of human reviewers to guarantee the highest standards of quality control. They validate the transcription with their insightful analysis, which strengthens our model and drives it toward constant progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea52673",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "Text that has been penned in a variety of styles, shapes, and sizes frequently appears in manuscripts. Machine learning models may struggle to recognize and accurately transcribe the text on some documents because of faded ink or other degradation.\n",
    "\n",
    "Manuscripts could have outmoded terminology, rudimentary spellings, or unusual vocabulary that is not frequently found in contemporary writing. For machine learning models that have been trained on recent text data, this can provide difficulties.\n",
    "\n",
    "The layout of manuscripts can be a mess, with text written in several columns, margins, or annotations. It can be difficult for machine learning algorithms to comprehend the proper reading order and content structure.\n",
    "\n",
    "Manuscripts may have noise, smudges, stains, or other artifacts that make it challenging to read the text. These aberrations can perplex machine learning algorithms and cause transcription mistakes.\n",
    "\n",
    "Different languages and scripts can be used to write manuscripts. The transcribing process becomes more difficult when models are created that can handle several scripts and languages.\n",
    "\n",
    "To verify the accuracy of the transcribed text, verification and quality control are required after transcription. This frequently necessitates human involvement, which can take time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d439d",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Hence, our project will provide a thorough solution for scanning manuscripts, improving image quality, performing image segmentation, extracting text, and stepping into the world of Natural Language Processing. We are committed to research and development and work hard to deliver the finest outcomes for the project. In order to guarantee the greatest caliber outcomes, we have been hard focusing on many factors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088b14c",
   "metadata": {},
   "source": [
    "### Referances\n",
    "\n",
    "1. https://stackoverflow.com/questions/72140311/image-segmentation-for-extracting-letters\n",
    "\n",
    "2. https://www.knowledgehut.com/blog/programming/working-with-pdf-files-in-python\n",
    "\n",
    "3. https://www.analyticsvidhya.com/blog/2021/09/image-segmentation-algorithms-with-implementation-in-python/\n",
    "\n",
    "4. https://gist.github.com/jgasteiz/431753041918dda13e6d/revisions\n",
    "\n",
    "5. https://stackoverflow.com/questions/26270821/segmenting-characters-from-image?rq=4\n",
    "\n",
    "6. https://pyimagesearch.com/2020/08/24/ocr-handwriting-recognition-with-opencv-keras-and-tensorflow/\n",
    "\n",
    "7. https://www.geeksforgeeks.org/extract-text-from-pdf-file-using-python/\n",
    "\n",
    "8. https://www.sciencedirect.com/topics/computer-science/character-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae833c4",
   "metadata": {},
   "source": [
    "# Volunteering\n",
    "\n",
    "Events – \n",
    "\n",
    "1. 8 Aug 2023 - B. R. Ambedkar University, Mhow(M.P.)\n",
    "2. 26 sept 2023 - Global Peace Foundation(GPF) India\n",
    "3. 22 dec 2023 - Mathematics Day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e793ee",
   "metadata": {},
   "source": [
    "#### Being a volunteer at the IKS (Indian Knowledge Systems) center is a fulfilling and engaging experience that entails actively taking part in and making a contribution to a variety of planned events and programs. The IKS center fosters a lively community interested in learning about all facets of Indian culture, heritage, and customs while acting as a focal point for promoting and maintaining Indian knowledge systems. When people volunteer for events, they take on a variety of duties and responsibilities that foster teamwork and a lively atmosphere. This is how the IKS center volunteer experience was described:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411a69",
   "metadata": {},
   "source": [
    "#### Similar tasks including helping with registration, caring to visitor needs, and guiding participants are part of volunteering at the aforementioned events, including Mathematics Day.\n",
    "\n",
    "Our center's commemoration of Mathematics Day, which falls on December 22nd, is a fun occasion that includes a number of interesting activities, such as volunteering and creating posters. This day is devoted to celebrating the achievements of mathematicians and encouraging an interest in and respect for the field of mathematics.\n",
    "\n",
    "1. Poster Making: Posters that emphasize the value, elegance, and practical uses of classical mathematics. The posters might showcase mathematical ideas, significant historical events, or captivating mathematical riddles. The goal of this project is to increase mathematics' visual attractiveness and accessibility for a wider range of users.\n",
    "\n",
    "2. Registration: Greeting guests, giving them the documents they need, and helping with the registration process are all part of volunteering for registration. An exciting day of mathematical inquiry is set in motion by the friendly and well-organized environment that volunteers provide.\n",
    "\n",
    "3. Tackling Queries: Responding to questions and provide details about the IKS center, its events, and any particular directions. This position is essential for providing a smooth experience for everyone involved and cultivating a culture where questions are encouraged and swiftly answered.\n",
    "\n",
    "4. Technical Assistance: In technology-oriented events, volunteers may provide technical support, ensuring that audio-visual equipment, presentations, and other technical aspects run smoothly.\n",
    "\n",
    "5. Community Engagement: Volunteers actively engage with event participants, fostering a sense of community and creating an inclusive environment where individuals can share their thoughts, experiences, and insights.\n",
    "\n",
    "6. Skill Development: Volunteering at the IKS center provides individuals with opportunities for skill development, including event coordination, teamwork, communication, and cultural understanding.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d1031",
   "metadata": {},
   "source": [
    "#### Overall, volunteering at events hosted by the IKS center not only supports the smooth execution of cultural and knowledge-sharing activities but also allows individuals to actively contribute to the promotion and preservation of Indian knowledge systems. It is a dynamic and collaborative experience that fosters a sense of community and shared cultural exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39144a22",
   "metadata": {},
   "source": [
    "# IKS WIKI Article\n",
    "\n",
    "Writing an article for the IKS (Indian Knowledge Systems) Wiki on Jaina Mathematical Manuscripts Digitalization with Machine Learning/Artificial Intelligence requires attention to both theoretical content and technical details in order to produce a thorough and user-friendly resource. The theoretical elements include an introduction to IKS and Jaina Mathematical Manuscripts Digitalization, a summary of its various elements, historical background, philosophical underpinnings, scientific accomplishments, cultural contributions, and current applicability. Technically speaking, emphasis is placed on collaborative editing, citation style, multimedia integration, linking, writing style and Wiki formatting with frontend technologies. This methodology guarantees a comprehensive article that is educational, captivating, and supportive of cooperative knowledge-sharing on the Wiki platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef2fe9",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "The six-month internship has been an incredible opportunity that has given me tremendous real-world experience and insights into the working world. I've got the chance to put my academic knowledge to use in practical situations, which has improved my abilities. My professional development has been greatly aided by working with talented individuals, taking on difficulties, and being exposed to a variety of tasks. In addition to broadening my knowledge in the field, this internship has stoked my desire to learn new things all the time. I am appreciative of the experiences, mentorship, and advice I received during this time, and I know that the knowledge and abilities I have gained will be a strong starting point for my future aspirations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
